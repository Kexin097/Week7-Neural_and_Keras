{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e96e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "154c2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7ef11cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('../Data/Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dd692fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f88f632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0    14.23        1.71  2.43          15.6        127           2.80   \n",
       "1    13.20        1.78  2.14          11.2        100           2.65   \n",
       "2    13.16        2.36  2.67          18.6        101           2.80   \n",
       "3    14.37        1.95  2.50          16.8        113           3.85   \n",
       "4    13.24        2.59  2.87          21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280  Proline  Customer_Segment  \n",
       "0   3.92     1065                 1  \n",
       "1   3.40     1050                 1  \n",
       "2   3.17     1185                 1  \n",
       "3   3.45     1480                 1  \n",
       "4   2.93      735                 1  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ced5851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Customer_Segment, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.Customer_Segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8426f724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_Intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Segment</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Alcohol               178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Ash_Alcanity          178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_Phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Flavanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_Phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_Intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "Customer_Segment      178.0    1.938202    0.775035    1.00    1.0000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Alcohol                13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Ash_Alcanity           19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_Phenols           2.355    2.8000     3.88  \n",
       "Flavanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_Phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_Intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  \n",
       "Customer_Segment        2.000    3.0000     3.00  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2a303702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol: 126\n",
      "Malic_Acid: 133\n",
      "Ash: 79\n",
      "Ash_Alcanity: 63\n",
      "Magnesium: 53\n",
      "Total_Phenols: 97\n",
      "Flavanoids: 132\n",
      "Nonflavanoid_Phenols: 39\n",
      "Proanthocyanins: 101\n",
      "Color_Intensity: 132\n",
      "Hue: 78\n",
      "OD280: 122\n",
      "Proline: 121\n",
      "Customer_Segment: 3\n"
     ]
    }
   ],
   "source": [
    "for col in wine:\n",
    "    print(col+\": \"+str(wine[col].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fe364031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Alcohol               178 non-null    float64\n",
      " 1   Malic_Acid            178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   Ash_Alcanity          178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   Total_Phenols         178 non-null    float64\n",
      " 6   Flavanoids            178 non-null    float64\n",
      " 7   Nonflavanoid_Phenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   Color_Intensity       178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280                 178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Customer_Segment      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "75130d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a5b159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = wine.sample(frac=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6b136be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>107</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.880</td>\n",
       "      <td>3.35</td>\n",
       "      <td>885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.100</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.030</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.120</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>12.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.21</td>\n",
       "      <td>20.4</td>\n",
       "      <td>103</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.82</td>\n",
       "      <td>870</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.41</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.040</td>\n",
       "      <td>3.47</td>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.130</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.68</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.36</td>\n",
       "      <td>17.2</td>\n",
       "      <td>104</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.230</td>\n",
       "      <td>2.87</td>\n",
       "      <td>990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13.28</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.84</td>\n",
       "      <td>15.5</td>\n",
       "      <td>110</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.090</td>\n",
       "      <td>2.78</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11.81</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.74</td>\n",
       "      <td>21.5</td>\n",
       "      <td>134</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.950</td>\n",
       "      <td>2.26</td>\n",
       "      <td>625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>13.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.46</td>\n",
       "      <td>20.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.45</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.980</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.28</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.880</td>\n",
       "      <td>2.42</td>\n",
       "      <td>488</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.24</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.29</td>\n",
       "      <td>17.5</td>\n",
       "      <td>103</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.00</td>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.890</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>13.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.42</td>\n",
       "      <td>14.0</td>\n",
       "      <td>111</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.87</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>510</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>13.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.230</td>\n",
       "      <td>2.46</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.050</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>13.74</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>16.4</td>\n",
       "      <td>118</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.920</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.220</td>\n",
       "      <td>2.87</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>11.56</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.23</td>\n",
       "      <td>28.5</td>\n",
       "      <td>119</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.87</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.930</td>\n",
       "      <td>3.69</td>\n",
       "      <td>465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12.60</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>94</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1.58</td>\n",
       "      <td>695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.890</td>\n",
       "      <td>2.78</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.39</td>\n",
       "      <td>625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.800</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>11.87</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.39</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3.64</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12.81</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.40</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.36</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.250</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "44     13.05        1.77  2.10          17.0        107           3.00   \n",
       "154    12.58        1.29  2.10          20.0        103           1.48   \n",
       "133    12.70        3.55  2.36          21.5        106           1.70   \n",
       "34     13.51        1.80  2.65          19.0        110           2.35   \n",
       "21     12.93        3.80  2.65          18.6        102           2.41   \n",
       "37     13.05        1.65  2.55          18.0         98           2.45   \n",
       "70     12.29        1.61  2.21          20.4        103           1.10   \n",
       "35     13.48        1.81  2.41          20.5        100           2.70   \n",
       "25     13.05        2.05  3.22          25.0        124           2.63   \n",
       "13     14.75        1.73  2.39          11.4         91           3.10   \n",
       "32     13.68        1.83  2.36          17.2        104           2.42   \n",
       "36     13.28        1.64  2.84          15.5        110           2.60   \n",
       "96     11.81        2.12  2.74          21.5        134           1.60   \n",
       "55     13.56        1.73  2.46          20.5        116           2.96   \n",
       "107    12.72        1.75  2.28          22.5         84           1.38   \n",
       "43     13.24        3.98  2.29          17.5        103           2.64   \n",
       "39     14.22        3.99  2.51          13.2        128           3.00   \n",
       "52     13.82        1.75  2.42          14.0        111           3.88   \n",
       "106    12.25        1.73  2.12          19.0         80           1.65   \n",
       "62     13.67        1.25  1.92          18.0         94           2.10   \n",
       "24     13.50        1.81  2.61          20.0         96           2.53   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "54     13.74        1.67  2.25          16.4        118           2.60   \n",
       "63     12.37        1.13  2.16          19.0         87           3.50   \n",
       "19     13.64        3.10  2.56          15.2        116           2.70   \n",
       "121    11.56        2.05  3.23          28.5        119           3.18   \n",
       "135    12.60        2.46  2.20          18.5         94           1.62   \n",
       "66     13.11        1.01  1.70          15.0         78           2.98   \n",
       "128    12.37        1.63  2.30          24.5         88           2.22   \n",
       "149    13.08        3.90  2.36          21.5        113           1.41   \n",
       "120    11.45        2.40  2.42          20.0         96           2.90   \n",
       "102    12.34        2.45  2.46          21.0         98           2.56   \n",
       "124    11.87        4.31  2.39          21.0         82           2.86   \n",
       "132    12.81        2.31  2.40          24.0         98           1.15   \n",
       "118    12.77        3.43  1.98          16.0         80           1.63   \n",
       "28     13.87        1.90  2.80          19.4        107           2.95   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity  \\\n",
       "44         3.00                  0.28             2.03             5.04   \n",
       "154        0.58                  0.53             1.40             7.60   \n",
       "133        1.20                  0.17             0.84             5.00   \n",
       "34         2.53                  0.29             1.54             4.20   \n",
       "21         2.41                  0.25             1.98             4.50   \n",
       "37         2.43                  0.29             1.44             4.25   \n",
       "70         1.02                  0.37             1.46             3.05   \n",
       "35         2.98                  0.26             1.86             5.10   \n",
       "25         2.68                  0.47             1.92             3.58   \n",
       "13         3.69                  0.43             2.81             5.40   \n",
       "32         2.69                  0.42             1.97             3.84   \n",
       "36         2.68                  0.34             1.36             4.60   \n",
       "96         0.99                  0.14             1.56             2.50   \n",
       "55         2.78                  0.20             2.45             6.25   \n",
       "107        1.76                  0.48             1.63             3.30   \n",
       "43         2.63                  0.32             1.66             4.36   \n",
       "39         3.04                  0.20             2.08             5.10   \n",
       "52         3.74                  0.32             1.87             7.05   \n",
       "106        2.03                  0.37             1.63             3.40   \n",
       "62         1.79                  0.32             0.73             3.80   \n",
       "24         2.61                  0.28             1.66             3.52   \n",
       "1          2.76                  0.26             1.28             4.38   \n",
       "54         2.90                  0.21             1.62             5.85   \n",
       "63         3.10                  0.19             1.87             4.45   \n",
       "19         3.03                  0.17             1.66             5.10   \n",
       "121        5.08                  0.47             1.87             6.00   \n",
       "135        0.66                  0.63             0.94             7.10   \n",
       "66         3.18                  0.26             2.28             5.30   \n",
       "128        2.45                  0.40             1.90             2.12   \n",
       "149        1.39                  0.34             1.14             9.40   \n",
       "120        2.79                  0.32             1.83             3.25   \n",
       "102        2.11                  0.34             1.31             2.80   \n",
       "124        3.03                  0.21             2.91             2.80   \n",
       "132        1.09                  0.27             0.83             5.70   \n",
       "118        1.25                  0.43             0.83             3.40   \n",
       "28         2.97                  0.37             1.76             4.50   \n",
       "\n",
       "       Hue  OD280  Proline  Customer_Segment  \n",
       "44   0.880   3.35      885                 1  \n",
       "154  0.580   1.55      640                 3  \n",
       "133  0.780   1.29      600                 3  \n",
       "34   1.100   2.87     1095                 1  \n",
       "21   1.030   3.52      770                 1  \n",
       "37   1.120   2.51     1105                 1  \n",
       "70   0.906   1.82      870                 2  \n",
       "35   1.040   3.47      920                 1  \n",
       "25   1.130   3.20      830                 1  \n",
       "13   1.250   2.73     1150                 1  \n",
       "32   1.230   2.87      990                 1  \n",
       "36   1.090   2.78      880                 1  \n",
       "96   0.950   2.26      625                 2  \n",
       "55   0.980   3.03     1120                 1  \n",
       "107  0.880   2.42      488                 2  \n",
       "43   0.820   3.00      680                 1  \n",
       "39   0.890   3.53      760                 1  \n",
       "52   1.010   3.26     1190                 1  \n",
       "106  1.000   3.17      510                 2  \n",
       "62   1.230   2.46      630                 2  \n",
       "24   1.120   3.82      845                 1  \n",
       "1    1.050   3.40     1050                 1  \n",
       "54   0.920   3.20     1060                 1  \n",
       "63   1.220   2.87      420                 2  \n",
       "19   0.960   3.36      845                 1  \n",
       "121  0.930   3.69      465                 2  \n",
       "135  0.730   1.58      695                 3  \n",
       "66   1.120   3.18      502                 2  \n",
       "128  0.890   2.78      342                 2  \n",
       "149  0.570   1.33      550                 3  \n",
       "120  0.800   3.39      625                 2  \n",
       "102  0.800   3.38      438                 2  \n",
       "124  0.750   3.64      380                 2  \n",
       "132  0.660   1.36      560                 3  \n",
       "118  0.700   2.12      372                 2  \n",
       "28   1.250   3.40      915                 1  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2182f6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 44, 154, 133,  34,  21,  37,  70,  35,  25,  13,  32,  36,  96,\n",
       "             55, 107,  43,  39,  52, 106,  62,  24,   1,  54,  63,  19, 121,\n",
       "            135,  66, 128, 149, 120, 102, 124, 132, 118,  28],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataframe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "658aabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = wine.drop(val_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b440b230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 142 samples for training and 36 for validation\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1b093a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot twist 1\n",
    "\n",
    "# to-categorical is only applicable to tensorflow, same concept as one-hot encorder/ label encorder etc\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3dbfd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_x(x):\n",
    "    if x == 1:\n",
    "        return 0\n",
    "    elif x == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b8879d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(wine):\n",
    "    wine = wine.copy()\n",
    "\n",
    "    wine[\"Customer_Segment\"]=wine[\"Customer_Segment\"].apply(lambda x:rep_x(x))\n",
    "    labels = to_categorical(wine.pop(\"Customer_Segment\"))      # pop is remove and store\n",
    "                            \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(wine), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(wine))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "da1e146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "44a3f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'Alcohol': <tf.Tensor: shape=(), dtype=float64, numpy=13.05>, 'Malic_Acid': <tf.Tensor: shape=(), dtype=float64, numpy=5.8>, 'Ash': <tf.Tensor: shape=(), dtype=float64, numpy=2.13>, 'Ash_Alcanity': <tf.Tensor: shape=(), dtype=float64, numpy=21.5>, 'Magnesium': <tf.Tensor: shape=(), dtype=int64, numpy=86>, 'Total_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=2.62>, 'Flavanoids': <tf.Tensor: shape=(), dtype=float64, numpy=2.65>, 'Nonflavanoid_Phenols': <tf.Tensor: shape=(), dtype=float64, numpy=0.3>, 'Proanthocyanins': <tf.Tensor: shape=(), dtype=float64, numpy=2.01>, 'Color_Intensity': <tf.Tensor: shape=(), dtype=float64, numpy=2.6>, 'Hue': <tf.Tensor: shape=(), dtype=float64, numpy=0.73>, 'OD280': <tf.Tensor: shape=(), dtype=float64, numpy=3.1>, 'Proline': <tf.Tensor: shape=(), dtype=int64, numpy=380>}\n",
      "Customer_Segment: tf.Tensor([0.000 1.000 0.000], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Customer_Segment:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "941788df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular batch number used is 32, 64, 128\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d877d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing steps\n",
    "from tensorflow.keras.layers import IntegerLookup    \n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3dd9057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature (normalize the feature)\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af6743",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1825dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "Alcohol = keras.Input(shape=(1,), name=\"Alcohol\")\n",
    "Malic_Acid = keras.Input(shape=(1,), name=\"Malic_Acid\")\n",
    "Ash = keras.Input(shape=(1,), name=\"Ash\")\n",
    "Ash_Alcanity = keras.Input(shape=(1,), name=\"Ash_Alcanity\")\n",
    "Magnesium = keras.Input(shape=(1,), name=\"Magnesium\")\n",
    "Total_Phenols = keras.Input(shape=(1,), name=\"Total_Phenols\")\n",
    "Flavanoids = keras.Input(shape=(1,), name=\"Flavanoids\")\n",
    "Nonflavanoid_Phenols = keras.Input(shape=(1,), name=\"Nonflavanoid_Phenols\")\n",
    "Proanthocyanins = keras.Input(shape=(1,), name=\"Proanthocyanins\")\n",
    "Color_Intensity = keras.Input(shape=(1,), name=\"Color_Intensity\")\n",
    "Hue = keras.Input(shape=(1,), name=\"Hue\")\n",
    "OD280 = keras.Input(shape=(1,), name=\"OD280\")\n",
    "Proline = keras.Input(shape=(1,), name=\"Proline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d54a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    Alcohol,\n",
    "    Malic_Acid,\n",
    "    Ash,\n",
    "    Ash_Alcanity,\n",
    "    Magnesium,\n",
    "    Total_Phenols,\n",
    "    Flavanoids,\n",
    "    Nonflavanoid_Phenols,\n",
    "    Proanthocyanins,\n",
    "    Color_Intensity,\n",
    "    Hue,\n",
    "    OD280,\n",
    "    Proline,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "586cea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Alcohol')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Malic_Acid')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Ash')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Ash_Alcanity')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Magnesium')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Total_Phenols')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Flavanoids')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Nonflavanoid_Phenols')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Proanthocyanins')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Color_Intensity')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Hue')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'OD280')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Proline')>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "788ee78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "Alcohol_encoded = encode_numerical_feature(Alcohol, \"Alcohol\", train_ds)\n",
    "Malic_Acid_encoded = encode_numerical_feature(Malic_Acid, \"Malic_Acid\", train_ds)\n",
    "Ash_encoded = encode_numerical_feature(Ash, \"Ash\", train_ds)\n",
    "Ash_Alcanity_encoded = encode_numerical_feature(Ash_Alcanity, \"Ash_Alcanity\", train_ds)\n",
    "Magnesium_encoded = encode_numerical_feature(Magnesium, \"Magnesium\", train_ds)\n",
    "Total_Phenols_encoded = encode_numerical_feature(Total_Phenols, \"Total_Phenols\", train_ds)\n",
    "Flavanoids_encoded = encode_numerical_feature(Flavanoids, \"Flavanoids\", train_ds)\n",
    "Nonflavanoid_Phenols_encoded = encode_numerical_feature(Nonflavanoid_Phenols, \"Nonflavanoid_Phenols\", train_ds)\n",
    "Proanthocyanins_encoded = encode_numerical_feature(Proanthocyanins, \"Proanthocyanins\", train_ds)\n",
    "Color_Intensity_encoded = encode_numerical_feature(Color_Intensity, \"Color_Intensity\", train_ds)\n",
    "Hue_encoded = encode_numerical_feature(Hue, \"Hue\", train_ds)\n",
    "OD280_encoded = encode_numerical_feature(OD280, \"OD280\", train_ds)\n",
    "Proline_encoded = encode_numerical_feature(Proline, \"Proline\", train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e588b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(\n",
    "    [\n",
    "    Alcohol,\n",
    "    Malic_Acid,\n",
    "    Ash,\n",
    "    Ash_Alcanity,\n",
    "    Magnesium,\n",
    "    Total_Phenols,\n",
    "    Flavanoids,\n",
    "    Nonflavanoid_Phenols,\n",
    "    Proanthocyanins,\n",
    "    Color_Intensity,\n",
    "    Hue,\n",
    "    OD280,\n",
    "    Proline,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02446760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 13) dtype=float32 (created by layer 'concatenate_5')>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8e8e32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Plot Twist 2\n",
    "output = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "#Plot Twist 3\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3eadaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 57ms/step - loss: 148.8507 - accuracy: 0.2958 - val_loss: 72.3716 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135.0336 - accuracy: 0.3239 - val_loss: 61.0782 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 124.0297 - accuracy: 0.2958 - val_loss: 49.9369 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 112.7577 - accuracy: 0.2817 - val_loss: 39.6895 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 120.7478 - accuracy: 0.2676 - val_loss: 31.6041 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 95.5196 - accuracy: 0.3239 - val_loss: 22.5198 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 99.8144 - accuracy: 0.3521 - val_loss: 14.7282 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 115.2603 - accuracy: 0.2606 - val_loss: 9.4462 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76.0026 - accuracy: 0.3873 - val_loss: 5.2153 - val_accuracy: 0.5278\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 88.6381 - accuracy: 0.3451 - val_loss: 3.5062 - val_accuracy: 0.5556\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 100.4357 - accuracy: 0.3028 - val_loss: 3.7424 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 86.0071 - accuracy: 0.3310 - val_loss: 4.1407 - val_accuracy: 0.5278\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77.7790 - accuracy: 0.3521 - val_loss: 5.6366 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 93.0991 - accuracy: 0.2817 - val_loss: 6.4559 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74.0843 - accuracy: 0.3592 - val_loss: 6.0926 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74.7463 - accuracy: 0.3662 - val_loss: 5.8732 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99.1828 - accuracy: 0.3169 - val_loss: 5.6162 - val_accuracy: 0.5833\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61.0648 - accuracy: 0.3451 - val_loss: 5.2737 - val_accuracy: 0.6389\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58.4118 - accuracy: 0.3944 - val_loss: 3.7904 - val_accuracy: 0.6944\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 60.1498 - accuracy: 0.3592 - val_loss: 2.5107 - val_accuracy: 0.7222\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61.8214 - accuracy: 0.3239 - val_loss: 2.1411 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66.4338 - accuracy: 0.2887 - val_loss: 1.9514 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60.5733 - accuracy: 0.3592 - val_loss: 1.6019 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50.4903 - accuracy: 0.4437 - val_loss: 1.3320 - val_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 63.8647 - accuracy: 0.3521 - val_loss: 1.3514 - val_accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50.5841 - accuracy: 0.3592 - val_loss: 1.4409 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51.0234 - accuracy: 0.4014 - val_loss: 1.5381 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50.3614 - accuracy: 0.3732 - val_loss: 1.6318 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57.6451 - accuracy: 0.3732 - val_loss: 1.3257 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.2111 - accuracy: 0.4437 - val_loss: 1.2670 - val_accuracy: 0.7222\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44.0936 - accuracy: 0.4155 - val_loss: 1.4894 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.2621 - accuracy: 0.4085 - val_loss: 1.8192 - val_accuracy: 0.6111\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.7251 - accuracy: 0.3592 - val_loss: 2.4647 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46.9953 - accuracy: 0.3239 - val_loss: 1.6322 - val_accuracy: 0.6111\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.6054 - accuracy: 0.4014 - val_loss: 1.3827 - val_accuracy: 0.6111\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.9594 - accuracy: 0.3592 - val_loss: 1.3891 - val_accuracy: 0.6944\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.1230 - accuracy: 0.3803 - val_loss: 1.4709 - val_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.6749 - accuracy: 0.3732 - val_loss: 1.6092 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.5362 - accuracy: 0.3662 - val_loss: 1.4002 - val_accuracy: 0.7222\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.9959 - accuracy: 0.4155 - val_loss: 1.4513 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.1371 - accuracy: 0.4014 - val_loss: 2.1915 - val_accuracy: 0.6944\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.0786 - accuracy: 0.4155 - val_loss: 3.0926 - val_accuracy: 0.6389\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.1410 - accuracy: 0.4577 - val_loss: 2.9418 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.0013 - accuracy: 0.4085 - val_loss: 2.8066 - val_accuracy: 0.5556\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.6763 - accuracy: 0.4577 - val_loss: 2.6919 - val_accuracy: 0.5278\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.3058 - accuracy: 0.4437 - val_loss: 2.3097 - val_accuracy: 0.5556\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21.9773 - accuracy: 0.4437 - val_loss: 2.0311 - val_accuracy: 0.5833\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.8291 - accuracy: 0.4085 - val_loss: 1.9593 - val_accuracy: 0.5833\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.0582 - accuracy: 0.4085 - val_loss: 1.6493 - val_accuracy: 0.8056\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.8520 - accuracy: 0.4366 - val_loss: 1.6809 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.6227 - accuracy: 0.5634 - val_loss: 1.8328 - val_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 19.3928 - accuracy: 0.4859 - val_loss: 1.8587 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 14.9950 - accuracy: 0.5141 - val_loss: 1.7451 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 16.2342 - accuracy: 0.4648 - val_loss: 1.6330 - val_accuracy: 0.7778\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.5597 - accuracy: 0.4085 - val_loss: 1.6841 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 15.3962 - accuracy: 0.4718 - val_loss: 1.6429 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15.2489 - accuracy: 0.4366 - val_loss: 1.6466 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.8998 - accuracy: 0.4718 - val_loss: 1.6651 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 13.3958 - accuracy: 0.5000 - val_loss: 1.8646 - val_accuracy: 0.7778\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7748 - accuracy: 0.4718 - val_loss: 2.1588 - val_accuracy: 0.7222\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 11.0860 - accuracy: 0.5000 - val_loss: 2.3620 - val_accuracy: 0.7222\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.3713 - accuracy: 0.5070 - val_loss: 2.5256 - val_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4159 - accuracy: 0.4507 - val_loss: 2.7975 - val_accuracy: 0.6944\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8444 - accuracy: 0.4507 - val_loss: 2.7157 - val_accuracy: 0.6944\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5448 - accuracy: 0.4507 - val_loss: 2.6469 - val_accuracy: 0.7222\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.4083 - accuracy: 0.5141 - val_loss: 2.5098 - val_accuracy: 0.7222\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8705 - accuracy: 0.5704 - val_loss: 2.2139 - val_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2115 - accuracy: 0.5423 - val_loss: 2.1407 - val_accuracy: 0.7222\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7745 - accuracy: 0.5634 - val_loss: 2.1716 - val_accuracy: 0.6944\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6669 - accuracy: 0.5563 - val_loss: 2.2071 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7812 - accuracy: 0.4718 - val_loss: 2.2863 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1730 - accuracy: 0.4789 - val_loss: 2.3138 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6761 - accuracy: 0.5915 - val_loss: 2.4127 - val_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1866 - accuracy: 0.5211 - val_loss: 2.5584 - val_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0283 - accuracy: 0.5704 - val_loss: 2.6375 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3434 - accuracy: 0.4789 - val_loss: 2.4583 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0820 - accuracy: 0.4859 - val_loss: 2.4153 - val_accuracy: 0.6944\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2870 - accuracy: 0.5704 - val_loss: 2.5188 - val_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6639 - accuracy: 0.4859 - val_loss: 2.5916 - val_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9782 - accuracy: 0.5563 - val_loss: 2.6794 - val_accuracy: 0.6944\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4842 - accuracy: 0.5282 - val_loss: 2.7110 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7630 - accuracy: 0.6056 - val_loss: 2.7362 - val_accuracy: 0.6111\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.3195 - accuracy: 0.5070 - val_loss: 2.6769 - val_accuracy: 0.6389\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1769 - accuracy: 0.5845 - val_loss: 2.7119 - val_accuracy: 0.6389\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0543 - accuracy: 0.5563 - val_loss: 2.6229 - val_accuracy: 0.6944\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7383 - accuracy: 0.5915 - val_loss: 2.4371 - val_accuracy: 0.6944\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5301 - accuracy: 0.6056 - val_loss: 2.3538 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7665 - accuracy: 0.5986 - val_loss: 2.3419 - val_accuracy: 0.6389\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4782 - accuracy: 0.5634 - val_loss: 2.3393 - val_accuracy: 0.6944\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6312 - accuracy: 0.6056 - val_loss: 2.3160 - val_accuracy: 0.6944\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4964 - accuracy: 0.5634 - val_loss: 2.3958 - val_accuracy: 0.6944\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5136 - accuracy: 0.5986 - val_loss: 2.4645 - val_accuracy: 0.6944\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6444 - accuracy: 0.5704 - val_loss: 2.5626 - val_accuracy: 0.6389\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8205 - accuracy: 0.6479 - val_loss: 2.4409 - val_accuracy: 0.6389\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8299 - accuracy: 0.5845 - val_loss: 2.2521 - val_accuracy: 0.6944\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1559 - accuracy: 0.5352 - val_loss: 2.1724 - val_accuracy: 0.6944\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6880 - accuracy: 0.5352 - val_loss: 2.2256 - val_accuracy: 0.6944\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2448 - accuracy: 0.6127 - val_loss: 2.3106 - val_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2796 - accuracy: 0.6056 - val_loss: 2.4737 - val_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7461 - accuracy: 0.6338 - val_loss: 2.6928 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f6256bc10>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69f3b625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0    14.23        1.71  2.43          15.6        127            2.8   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "\n",
       "   OD280  Proline  Customer_Segment  \n",
       "0   3.92     1065                 1  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample with your own, do testing\n",
    "\n",
    "test = wine.head(1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e9bf4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# shortcut to convert dataframe to dict\n",
    "test.drop('Customer_Segment',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "673e1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KEXIN_~1\\AppData\\Local\\Temp/ipykernel_19812/1745375697.py:1: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  sample = test.to_dict('r')[0]\n"
     ]
    }
   ],
   "source": [
    "sample = test.to_dict('r')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0f0e312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alcohol': 14.23,\n",
       " 'Malic_Acid': 1.71,\n",
       " 'Ash': 2.43,\n",
       " 'Ash_Alcanity': 15.6,\n",
       " 'Magnesium': 127,\n",
       " 'Total_Phenols': 2.8,\n",
       " 'Flavanoids': 3.06,\n",
       " 'Nonflavanoid_Phenols': 0.28,\n",
       " 'Proanthocyanins': 2.29,\n",
       " 'Color_Intensity': 5.64,\n",
       " 'Hue': 1.04,\n",
       " 'OD280': 3.92,\n",
       " 'Proline': 1065}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3e0e804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "67e1e385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alcohol': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.23], dtype=float32)>,\n",
       " 'Malic_Acid': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.71], dtype=float32)>,\n",
       " 'Ash': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.43], dtype=float32)>,\n",
       " 'Ash_Alcanity': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.6], dtype=float32)>,\n",
       " 'Magnesium': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([127])>,\n",
       " 'Total_Phenols': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.8], dtype=float32)>,\n",
       " 'Flavanoids': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.06], dtype=float32)>,\n",
       " 'Nonflavanoid_Phenols': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.28], dtype=float32)>,\n",
       " 'Proanthocyanins': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.29], dtype=float32)>,\n",
       " 'Color_Intensity': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.64], dtype=float32)>,\n",
       " 'Hue': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.04], dtype=float32)>,\n",
       " 'OD280': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.92], dtype=float32)>,\n",
       " 'Proline': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1065])>}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8377842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a50316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97407496, 0.01917664, 0.0067484 ]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bef0d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "17fe45d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.974, 0.019, 0.007]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2bba9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This wine belongs to Type 0 as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"This wine belongs to Type %d as evaluated by our model.\" % (predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2303b",
   "metadata": {},
   "source": [
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "76178cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs_demo = []\n",
    "\n",
    "for col in wine:\n",
    "#   Condition to detect categorical columns\n",
    "    if(wine[col].nunique()<=5):\n",
    "        #   Condition to detect categorical columns + integer\n",
    "        if(wine[col].dtypes=='int64'):\n",
    "            all_inputs_demo.append(keras.Input(shape=(1,), name=col, dtype=\"int64\"))\n",
    "        #   Condition to detect categorical columns + string\n",
    "        else:\n",
    "            all_inputs_demo.append(keras.Input(shape=(1,), name=col, dtype=\"string\"))\n",
    "    #   Condition to detect numerical\n",
    "    else:\n",
    "        all_inputs_demo.append(keras.Input(shape=(1,), name=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1abdee6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Alcohol')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Malic_Acid')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Ash')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Ash_Alcanity')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Magnesium')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Total_Phenols')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Flavanoids')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Nonflavanoid_Phenols')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Proanthocyanins')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Color_Intensity')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Hue')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'OD280')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Proline')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'Customer_Segment')>]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0e4f254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname= wine.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c2db7309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol\n",
      "Malic_Acid\n",
      "Ash\n",
      "Ash_Alcanity\n",
      "Magnesium\n",
      "Total_Phenols\n",
      "Flavanoids\n",
      "Nonflavanoid_Phenols\n",
      "Proanthocyanins\n",
      "Color_Intensity\n",
      "Hue\n",
      "OD280\n",
      "Proline\n"
     ]
    }
   ],
   "source": [
    "for index,value in enumerate(colname):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ee2d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded_demo =[]\n",
    "\n",
    "for index,value in enumerate(colname):\n",
    "#   Condition to detect categorical columns\n",
    "    if(wine[value].nunique()<=5):\n",
    "        #   Condition to detect categorical columns + integer\n",
    "        if(wine[value].dtypes=='int64'):\n",
    "            features_encoded_demo.append(encode_categorical_feature(all_inputs_demo[index], value, train_ds, False))\n",
    "        #   Condition to detect categorical columns + string\n",
    "        else:\n",
    "            features_encoded_demo.append(encode_categorical_feature(all_inputs_demo[index], value, train_ds, True))\n",
    "    #   Condition to detect numerical\n",
    "    else:\n",
    "        features_encoded_demo.append(encode_numerical_feature(all_inputs_demo[index], value, train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3139ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded_demo =[]\n",
    "for index,value in enumerate(colname):\n",
    "    features_encoded_demo.append(encode_numerical_feature(all_inputs_demo[index], value, train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "02e8adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = layers.concatenate(features_encoded_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "94d9af54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 13) dtype=float32 (created by layer 'concatenate_7')>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4efa8ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='Alcohol'), name='Alcohol', description=\"created by layer 'Alcohol'\") at layer \"normalization_106\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KEXIN_~1\\AppData\\Local\\Temp/ipykernel_19812/1400562748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Plot Twist 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#Plot Twist 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[0;32m    230\u001b[0m         self.inputs, self.outputs)\n\u001b[0;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1037\u001b[0m                 \u001b[1;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[1;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='Alcohol'), name='Alcohol', description=\"created by layer 'Alcohol'\") at layer \"normalization_106\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Plot Twist 2\n",
    "output = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "#Plot Twist 3\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a913839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "510abe3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 183, in assert_input_compatibility\n        raise ValueError(f'Missing data for input \"{name}\". '\n\n    ValueError: Missing data for input \"Customer_Segment\". You passed a data dictionary with keys ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium', 'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols', 'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline']. Expected the following keys: ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium', 'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols', 'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline', 'Customer_Segment']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KEXIN_~1\\AppData\\Local\\Temp/ipykernel_19812/2715139496.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kexin_lee\\Anaconda3\\envs\\python-dscourse\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 183, in assert_input_compatibility\n        raise ValueError(f'Missing data for input \"{name}\". '\n\n    ValueError: Missing data for input \"Customer_Segment\". You passed a data dictionary with keys ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium', 'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols', 'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline']. Expected the following keys: ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium', 'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols', 'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline', 'Customer_Segment']\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c25a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
